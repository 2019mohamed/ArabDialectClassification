{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PassiveAggressive_MLP_Online_fair.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Rp68iGtrMm2_JkPY5cQy9iX8muFnbQ8g",
      "authorship_tag": "ABX9TyN2xdEFGnsvDhdbhZvyA7Ob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2019mohamed/ArabDialectClassification/blob/master/PassiveAggressive_MLP_Online_fair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "c7uJjjD2J_7E",
        "outputId": "470c19e7-cdfe-4da0-e9f9-64b866861709"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-312a0ddf-7e0d-403b-b8ff-c1b2bd0c4bcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>بالنهايه ينتفض يغير</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يح...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>مبين كلامه خليجي</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وين الغيبه اخ محمد</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458192</th>\n",
              "      <td>مبسوطين منك اللي باسطانا</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458193</th>\n",
              "      <td>والله ماينده ابش يختي</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458194</th>\n",
              "      <td>شو عملنا حنا تهربي مننا احنا مساكين ليش بتعملي...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458195</th>\n",
              "      <td>الله يبارك وبالعافيه</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458196</th>\n",
              "      <td>السحله ضيفي بتطلع سحليه</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>458197 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-312a0ddf-7e0d-403b-b8ff-c1b2bd0c4bcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-312a0ddf-7e0d-403b-b8ff-c1b2bd0c4bcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-312a0ddf-7e0d-403b-b8ff-c1b2bd0c4bcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 new_text  label\n",
              "0                                     بالنهايه ينتفض يغير      0\n",
              "1       يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يح...      0\n",
              "2                                        مبين كلامه خليجي      0\n",
              "3                               يسلملي مرورك وروحك الحلوه      0\n",
              "4                                      وين الغيبه اخ محمد      0\n",
              "...                                                   ...    ...\n",
              "458192                           مبسوطين منك اللي باسطانا     17\n",
              "458193                              والله ماينده ابش يختي     17\n",
              "458194  شو عملنا حنا تهربي مننا احنا مساكين ليش بتعملي...     17\n",
              "458195                               الله يبارك وبالعافيه     17\n",
              "458196                            السحله ضيفي بتطلع سحليه     17\n",
              "\n",
              "[458197 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/two_clo_dialect_dataset.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts().min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A5YhEkgyVEs",
        "outputId": "aed10f57-94a3-4d02-f166-b485f17fb2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9246"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = df['new_text'].astype('str').tolist()\n",
        "labels = df['label'].tolist()"
      ],
      "metadata": {
        "id": "KFgmcoV1urKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_index ():\n",
        "  freqs = df['label'].value_counts()\n",
        "\n",
        "  start = [0 for _ in range(18)]\n",
        "  start[0] = 0\n",
        "  for c in range(1,18):\n",
        "      start[c] += freqs[c-1] + start[c-1]  \n",
        "  indexes = []# (mini , maxi+1) for all classes\n",
        "  for c in range(18):\n",
        "      indexes.append(  (start[c] , start[c] + freqs[c]) )\n",
        "    \n",
        "  return indexes"
      ],
      "metadata": {
        "id": "DM0b4IVgttNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def sample_data (data , label ,intervals, lim = 1000):\n",
        "  data = np.array(data)\n",
        "  label = np.array(label)\n",
        "  ret = np.array([])\n",
        "  retl = np.array([])\n",
        "  for i in range(18):\n",
        "    l = intervals[i][0]\n",
        "    h = intervals[i][1]\n",
        "\n",
        "\n",
        "    index = np.random.choice(range(l,h), size = lim , replace = False)\n",
        "\n",
        "\n",
        "    ret = np.concatenate((ret , data[index]), axis = 0)\n",
        "    retl = np.concatenate((retl , label[index]), axis = 0)\n",
        "\n",
        "  return ret,retl"
      ],
      "metadata": {
        "id": "dQGW2tN0uzIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Zqj1H9Z8u44M"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec = pickle.load(open('/content/drive/MyDrive/vectorizer.pkl', 'rb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huGVdjAhu8V-",
        "outputId": "dcd2b1aa-2da2-49e1-f84f-679822e8fcdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = get_index()"
      ],
      "metadata": {
        "id": "8Jc_bfXMvGdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler , BatchSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from scipy.sparse import coo_matrix"
      ],
      "metadata": {
        "id": "CKp3kWvOvHjl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"MLP with linear output\"\"\"\n",
        "    def __init__(self, num_layers, input_dim, hidden_dim, output_dim):\n",
        "        \"\"\"MLP layers construction\n",
        "        Paramters\n",
        "        ---------\n",
        "        num_layers: int\n",
        "            The number of linear layers\n",
        "        input_dim: int\n",
        "            The dimensionality of input features\n",
        "        hidden_dim: int\n",
        "            The dimensionality of hidden units at ALL layers\n",
        "        output_dim: int\n",
        "            The number of classes for prediction\n",
        "        \"\"\"\n",
        "        super(MLP, self).__init__()\n",
        "        self.linear_or_not = True  # default is linear model\n",
        "        self.num_layers = num_layers\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        if num_layers < 1:\n",
        "            raise ValueError(\"number of layers should be positive!\")\n",
        "        elif num_layers == 1:\n",
        "            # Linear model\n",
        "            self.linear = nn.Linear(input_dim, output_dim)\n",
        "        else:\n",
        "            # Multi-layer model\n",
        "            self.linear_or_not = False\n",
        "            self.linears = torch.nn.ModuleList()\n",
        "            self.batch_norms = torch.nn.ModuleList()\n",
        "\n",
        "            self.linears.append(nn.Linear(input_dim, hidden_dim))\n",
        "            for layer in range(num_layers - 2):\n",
        "                self.linears.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            self.linears.append(nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "            #for layer in range(num_layers - 1):\n",
        "             #   self.batch_norms.append(nn.BatchNorm1d((hidden_dim)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.linear_or_not:\n",
        "            # If linear model\n",
        "            return self.linear(x)\n",
        "        else:\n",
        "            # If MLP\n",
        "            h = x\n",
        "            for i in range(self.num_layers - 1):\n",
        "                h = F.relu(self.linears[i](h))\n",
        "            return self.linears[-1](h)"
      ],
      "metadata": {
        "id": "kgkXTLMxvMv0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "metadata": {
        "id": "T5ELMjEuvSW8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_classifiy ():\n",
        "  sample_corpus, sample_label = sample_data(corpus , labels, indexes)\n",
        "  X = vec.transform(sample_corpus)\n",
        "  X = coo_matrix(X)\n",
        "  tensor_X = torch.sparse_coo_tensor([X.row , X.col],X.data , dtype = torch.float)\n",
        "  reducer = MLP(2,tensor_X.shape[1],1000,10000)\n",
        "  reducer.apply(init_weights)\n",
        "  Z = reducer(tensor_X)\n",
        "  Z = Z.detach().numpy()\n",
        "  permute = np.random.permutation(Z.shape[0])\n",
        "  Z = Z[permute]\n",
        "  sample_label = sample_label[permute]\n",
        "  return Z , sample_label"
      ],
      "metadata": {
        "id": "r5E8ju2wwVMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "2TqcGguovW9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = []\n",
        "ACCs= []\n",
        "confusion_matrixs = []"
      ],
      "metadata": {
        "id": "LR7tt1R0wzvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PassiveAggressiveClassifier(loss = 'squared_hinge')"
      ],
      "metadata": {
        "id": "7_6mo4Ofw62m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_batch = 50\n",
        "\n",
        "for i in range(num_batch):\n",
        "  v , l = data_classifiy()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(v,l, test_size=0.2, random_state=42)\n",
        "  model.partial_fit(X_train ,y_train,classes=np.unique(l))\n",
        "  predict = model.predict(X_test)\n",
        "  predicts.append(predict)\n",
        "  ACCs.append(accuracy_score(y_test , predict)*100)\n",
        "  confusion_matrixs.append(confusion_matrix(y_test , predict, labels = range(0,18)))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYQ4w9FnwY78",
        "outputId": "2f31a6b0-4d37-4f50-c7f3-5b16f548102f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ACCs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKWBwD0axrt7",
        "outputId": "f849a6b2-7f8c-4b39-9440-5aa5166fb4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12.087542087542086,\n",
              " 5.505050505050505,\n",
              " 5.875420875420875,\n",
              " 8.98989898989899,\n",
              " 5.387205387205387,\n",
              " 10.84175084175084,\n",
              " 6.784511784511785,\n",
              " 5.589225589225589,\n",
              " 6.616161616161616,\n",
              " 9.68013468013468,\n",
              " 9.764309764309765,\n",
              " 5.774410774410774,\n",
              " 10.404040404040405,\n",
              " 5.353535353535353,\n",
              " 6.700336700336701,\n",
              " 9.94949494949495,\n",
              " 6.262626262626263,\n",
              " 6.279461279461279,\n",
              " 6.936026936026936,\n",
              " 9.545454545454547,\n",
              " 9.62962962962963,\n",
              " 8.080808080808081,\n",
              " 9.612794612794612,\n",
              " 6.111111111111111,\n",
              " 7.171717171717172,\n",
              " 8.93939393939394,\n",
              " 5.437710437710438,\n",
              " 6.1952861952861955,\n",
              " 9.62962962962963,\n",
              " 6.6498316498316505,\n",
              " 8.4006734006734,\n",
              " 9.848484848484848,\n",
              " 6.1952861952861955,\n",
              " 5.656565656565657,\n",
              " 8.905723905723907,\n",
              " 8.93939393939394,\n",
              " 5.505050505050505,\n",
              " 5.757575757575758,\n",
              " 8.030303030303031,\n",
              " 5.656565656565657,\n",
              " 5.488215488215488,\n",
              " 6.952861952861952,\n",
              " 8.67003367003367,\n",
              " 6.616161616161616,\n",
              " 5.942760942760943,\n",
              " 5.9259259259259265,\n",
              " 5.606060606060606,\n",
              " 8.013468013468012,\n",
              " 5.63973063973064,\n",
              " 5.757575757575758,\n",
              " 6.498316498316499,\n",
              " 8.282828282828284,\n",
              " 5.387205387205387,\n",
              " 8.602693602693602,\n",
              " 9.20875420875421]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.average(np.array(ACCs))\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df5heIDQAiln",
        "outputId": "13509ead-e396-4955-a022-cce54882a970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.132777777777779"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(confusion_matrixs[0])"
      ],
      "metadata": {
        "id": "tpHsBoTOA_cI",
        "outputId": "90db6089-2ad9-42cf-d7df-14559fd766d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc478f5dc10>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pickle.dump(model,open('PA.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "y5MiqRamxv8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will code the API for the model using flask framework"
      ],
      "metadata": {
        "id": "AvqXGdV3LuCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tashaphyne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHMwDZxvIbEe",
        "outputId": "231bc012-56a5-4b6f-9da9-c9877661ca1d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tashaphyne\n",
            "  Downloading Tashaphyne-0.3.6-py3-none-any.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 13.3 MB/s \n",
            "\u001b[?25hCollecting pyarabic\n",
            "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic->tashaphyne) (1.15.0)\n",
            "Installing collected packages: pyarabic, tashaphyne\n",
            "Successfully installed pyarabic-0.6.14 tashaphyne-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarabic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdrzTu70IkKr",
        "outputId": "6f1743c8-3a15-43fa-a783-be69617423ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.7/dist-packages (0.6.14)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFz3EZD-IttT",
        "outputId": "5d34a0d1-2b51-4bee-fb19-4be75b05f772"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 112 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 122 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 163 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 174 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 12.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=5163e285f3e2b1e266008268532443735964544337508cef68fd4d14810e5f41\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSwZ2ZzEI8Sd",
        "outputId": "8ecb7122-4222-490e-b1ed-4cbdfb723b51"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWbeV_X5JLqj",
        "outputId": "4be06337-13ab-428b-f939-89f09d49b8b7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning data\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "from tashaphyne.stemming import ArabicLightStemmer\n",
        "#from nltk.stem.isri import ISRIStemmer\n",
        "import pyarabic.araby as araby\n",
        "import re\n",
        "import emoji\n",
        "\n",
        "\n",
        "stops = set(stopwords.words(\"arabic\"))\n",
        "stop_word_comp = {\"،\",\"آض\",\"آمينَ\",\"آه\",\"آهاً\",\"آي\",\"أ\",\"أب\",\"أجل\",\"أجمع\",\"أخ\",\"أخذ\",\"أصبح\",\"أضحى\",\"أقبل\",\"أقل\",\"أكثر\",\"ألا\",\"أم\",\"أما\",\"أمامك\",\"أمامكَ\",\"أمسى\",\"أمّا\",\"أن\",\"أنا\",\"أنت\",\"أنتم\",\"أنتما\",\"أنتن\",\"أنتِ\",\"أنشأ\",\"أنّى\",\"أو\",\"أوشك\",\"أولئك\",\"أولئكم\",\"أولاء\",\"أولالك\",\"أوّهْ\",\"أي\",\"أيا\",\"أين\",\"أينما\",\"أيّ\",\"أَنَّ\",\"أََيُّ\",\"أُفٍّ\",\"إذ\",\"إذا\",\"إذاً\",\"إذما\",\"إذن\",\"إلى\",\"إليكم\",\"إليكما\",\"إليكنّ\",\"إليكَ\",\"إلَيْكَ\",\"إلّا\",\"إمّا\",\"إن\",\"إنّما\",\"إي\",\"إياك\",\"إياكم\",\"إياكما\",\"إياكن\",\"إيانا\",\"إياه\",\"إياها\",\"إياهم\",\"إياهما\",\"إياهن\",\"إياي\",\"إيهٍ\",\"إِنَّ\",\"ا\",\"ابتدأ\",\"اثر\",\"اجل\",\"احد\",\"اخرى\",\"اخلولق\",\"اذا\",\"اربعة\",\"ارتدّ\",\"استحال\",\"اطار\",\"اعادة\",\"اعلنت\",\"اف\",\"اكثر\",\"اكد\",\"الألاء\",\"الألى\",\"الا\",\"الاخيرة\",\"الان\",\"الاول\",\"الاولى\",\"التى\",\"التي\",\"الثاني\",\"الثانية\",\"الذاتي\",\"الذى\",\"الذي\",\"الذين\",\"السابق\",\"الف\",\"اللائي\",\"اللاتي\",\"اللتان\",\"اللتيا\",\"اللتين\",\"اللذان\",\"اللذين\",\"اللواتي\",\"الماضي\",\"المقبل\",\"الوقت\",\"الى\",\"اليوم\",\"اما\",\"امام\",\"امس\",\"ان\",\"انبرى\",\"انقلب\",\"انه\",\"انها\",\"او\",\"اول\",\"اي\",\"ايار\",\"ايام\",\"ايضا\",\"ب\",\"بات\",\"باسم\",\"بان\",\"بخٍ\",\"برس\",\"بسبب\",\"بسّ\",\"بشكل\",\"بضع\",\"بطآن\",\"بعد\",\"بعض\",\"بك\",\"بكم\",\"بكما\",\"بكن\",\"بل\",\"بلى\",\"بما\",\"بماذا\",\"بمن\",\"بن\",\"بنا\",\"به\",\"بها\",\"بي\",\"بيد\",\"بين\",\"بَسْ\",\"بَلْهَ\",\"بِئْسَ\",\"تانِ\",\"تانِك\",\"تبدّل\",\"تجاه\",\"تحوّل\",\"تلقاء\",\"تلك\",\"تلكم\",\"تلكما\",\"تم\",\"تينك\",\"تَيْنِ\",\"تِه\",\"تِي\",\"ثلاثة\",\"ثم\",\"ثمّ\",\"ثمّة\",\"ثُمَّ\",\"جعل\",\"جلل\",\"جميع\",\"جير\",\"حار\",\"حاشا\",\"حاليا\",\"حاي\",\"حتى\",\"حرى\",\"حسب\",\"حم\",\"حوالى\",\"حول\",\"حيث\",\"حيثما\",\"حين\",\"حيَّ\",\"حَبَّذَا\",\"حَتَّى\",\"حَذارِ\",\"خلا\",\"خلال\",\"دون\",\"دونك\",\"ذا\",\"ذات\",\"ذاك\",\"ذانك\",\"ذانِ\",\"ذلك\",\"ذلكم\",\"ذلكما\",\"ذلكن\",\"ذو\",\"ذوا\",\"ذواتا\",\"ذواتي\",\"ذيت\",\"ذينك\",\"ذَيْنِ\",\"ذِه\",\"ذِي\",\"راح\",\"رجع\",\"رويدك\",\"ريث\",\"رُبَّ\",\"زيارة\",\"سبحان\",\"سرعان\",\"سنة\",\"سنوات\",\"سوف\",\"سوى\",\"سَاءَ\",\"سَاءَمَا\",\"شبه\",\"شخصا\",\"شرع\",\"شَتَّانَ\",\"صار\",\"صباح\",\"صفر\",\"صهٍ\",\"صهْ\",\"ضد\",\"ضمن\",\"طاق\",\"طالما\",\"طفق\",\"طَق\",\"ظلّ\",\"عاد\",\"عام\",\"عاما\",\"عامة\",\"عدا\",\"عدة\",\"عدد\",\"عدم\",\"عسى\",\"عشر\",\"عشرة\",\"علق\",\"على\",\"عليك\",\"عليه\",\"عليها\",\"علًّ\",\"عن\",\"عند\",\"عندما\",\"عوض\",\"عين\",\"عَدَسْ\",\"عَمَّا\",\"غدا\",\"غير\",\"ـ\",\"ف\",\"فان\",\"فلان\",\"فو\",\"فى\",\"في\",\"فيم\",\"فيما\",\"فيه\",\"فيها\",\"قال\",\"قام\",\"قبل\",\"قد\",\"قطّ\",\"قلما\",\"قوة\",\"كأنّما\",\"كأين\",\"كأيّ\",\"كأيّن\",\"كاد\",\"كان\",\"كانت\",\"كذا\",\"كذلك\",\"كرب\",\"كل\",\"كلا\",\"كلاهما\",\"كلتا\",\"كلم\",\"كليكما\",\"كليهما\",\"كلّما\",\"كلَّا\",\"كم\",\"كما\",\"كي\",\"كيت\",\"كيف\",\"كيفما\",\"كَأَنَّ\",\"كِخ\",\"لئن\",\"لا\",\"لات\",\"لاسيما\",\"لدن\",\"لدى\",\"لعمر\",\"لقاء\",\"لك\",\"لكم\",\"لكما\",\"لكن\",\"لكنَّما\",\"لكي\",\"لكيلا\",\"للامم\",\"لم\",\"لما\",\"لمّا\",\"لن\",\"لنا\",\"له\",\"لها\",\"لو\",\"لوكالة\",\"لولا\",\"لوما\",\"لي\",\"لَسْتَ\",\"لَسْتُ\",\"لَسْتُم\",\"لَسْتُمَا\",\"لَسْتُنَّ\",\"لَسْتِ\",\"لَسْنَ\",\"لَعَلَّ\",\"لَكِنَّ\",\"لَيْتَ\",\"لَيْسَ\",\"لَيْسَا\",\"لَيْسَتَا\",\"لَيْسَتْ\",\"لَيْسُوا\",\"لَِسْنَا\",\"ما\",\"ماانفك\",\"مابرح\",\"مادام\",\"ماذا\",\"مازال\",\"مافتئ\",\"مايو\",\"متى\",\"مثل\",\"مذ\",\"مساء\",\"مع\",\"معاذ\",\"مقابل\",\"مكانكم\",\"مكانكما\",\"مكانكنّ\",\"مكانَك\",\"مليار\",\"مليون\",\"مما\",\"ممن\",\"من\",\"منذ\",\"منها\",\"مه\",\"مهما\",\"مَنْ\",\"مِن\",\"نحن\",\"نحو\",\"نعم\",\"نفس\",\"نفسه\",\"نهاية\",\"نَخْ\",\"نِعِمّا\",\"نِعْمَ\",\"ها\",\"هاؤم\",\"هاكَ\",\"هاهنا\",\"هبّ\",\"هذا\",\"هذه\",\"هكذا\",\"هل\",\"هلمَّ\",\"هلّا\",\"هم\",\"هما\",\"هن\",\"هنا\",\"هناك\",\"هنالك\",\"هو\",\"هي\",\"هيا\",\"هيت\",\"هيّا\",\"هَؤلاء\",\"هَاتانِ\",\"هَاتَيْنِ\",\"هَاتِه\",\"هَاتِي\",\"هَجْ\",\"هَذا\",\"هَذانِ\",\"هَذَيْنِ\",\"هَذِه\",\"هَذِي\",\"هَيْهَاتَ\",\"و\",\"و6\",\"وا\",\"واحد\",\"واضاف\",\"واضافت\",\"واكد\",\"وان\",\"واهاً\",\"واوضح\",\"وراءَك\",\"وفي\",\"وقال\",\"وقالت\",\"وقد\",\"وقف\",\"وكان\",\"وكانت\",\"ولا\",\"ولم\",\"ومن\",\"مَن\",\"وهو\",\"وهي\",\"ويكأنّ\",\"وَيْ\",\"وُشْكَانََ\",\"يكون\",\"يمكن\",\"يوم\",\"ّأيّان\"}\n",
        "ArListem = ArabicLightStemmer()\n",
        "\n",
        "def stem(text):\n",
        "    zen = TextBlob(text)\n",
        "    words = zen.words\n",
        "    cleaned = list()\n",
        "    for w in words:\n",
        "        ArListem.light_stem(w)\n",
        "        cleaned.append(ArListem.get_root())\n",
        "    return \" \".join(cleaned)\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    zen = TextBlob(text)\n",
        "    words = zen.words\n",
        "    return \" \".join([w for w in words if not w in stops and not w in stop_word_comp and len(w) >= 2])\n",
        "\n",
        "\n",
        "def normalizeArabic(text):\n",
        "    text = text.strip()\n",
        "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"ء\", text)\n",
        "    text = re.sub(\"ئ\", \"ء\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    noise = re.compile(\"\"\" ّ    | # Tashdid\n",
        "                             َ    | # Fatha\n",
        "                             ً    | # Tanwin Fath\n",
        "                             ُ    | # Damma\n",
        "                             ٌ    | # Tanwin Damm\n",
        "                             ِ    | # Kasra\n",
        "                             ٍ    | # Tanwin Kasr\n",
        "                             ْ    | # Sukun\n",
        "                             ـ     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)\n",
        "    text = re.sub(noise, '', text)\n",
        "    text = re.sub(r'(.)\\1+', r\"\\1\\1\", text) # Remove longation\n",
        "    return araby.strip_tashkeel(text)\n",
        "\n",
        "def extract_hashtag(text):\n",
        "    \n",
        "    hash_list = ([re.sub(r\"(\\W+)$\", \"\", i) for i in text.split() if i.startswith(\"#\")])\n",
        "    word_list = []\n",
        "    for word in hash_list :\n",
        "        word_list.extend(split_hashtag_to_words(word))\n",
        "    return word_list\n",
        "\n",
        "def split_hashtag_to_words(tag):\n",
        "    tag = tag.replace('#','')\n",
        "    tags = tag.split('_')\n",
        "    if len(tags) > 1 :\n",
        "        \n",
        "        return tags\n",
        "    pattern = re.compile(r\"[A-Z][a-z]+|\\d+|[A-Z]+(?![a-z])\")\n",
        "    return pattern.findall(tag)\n",
        "\n",
        "def clean_hashtag(text):\n",
        "    words = text.split()\n",
        "    text = list()\n",
        "    for word in words:\n",
        "        if is_hashtag(word):\n",
        "            text.extend(extract_hashtag(word))\n",
        "        else:\n",
        "            text.append(word)\n",
        "    return \" \".join(text)\n",
        "\n",
        "def is_hashtag(word):\n",
        "    if word.startswith(\"#\"):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                                   u\"\\U00002702-\\U000027B0\"\n",
        "                                   u\"\\U000024C2-\\U0001F251\"\n",
        "                                   u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
        "                                   u\"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n",
        "                                   u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
        "                                   u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
        "                                   \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    text = emoji.demojize(text)\n",
        "    return text\n",
        "  \n",
        "def clean_tweet(text):\n",
        "    text = re.sub('#\\d+K\\d+', ' ', text)  # years like 2K19\n",
        "    text = re.sub('http\\S+\\s*', ' ', text)  # remove URLs\n",
        "    text = re.sub('RT|cc', ' ', text)  # remove RT and cc\n",
        "    text = re.sub('@[^\\s]+',' ',text)\n",
        "    text = clean_hashtag(text)\n",
        "    text = remove_emoji(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "    \n",
        "def clean_text (text):\n",
        "    ## Clean for tweets\n",
        "    text = clean_tweet(text)\n",
        "    ## Remove punctuations\n",
        "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)  # remove punctuation\n",
        "    ## remove extra whitespace\n",
        "    text = re.sub('\\s+', ' ', text)  \n",
        "    ## Remove stop words\n",
        "    text = remove_stop_words(text)\n",
        "    ## Remove numbers\n",
        "    text = re.sub(\"\\d+\", \" \", text)\n",
        "    ## Remove Tashkeel\n",
        "    text = normalizeArabic(text)\n",
        "    \n",
        "    text = re.sub('[A-Za-z]+',' ',text)\n",
        "    \n",
        "    text = re.sub(r'\\\\u[A-Za-z0-9\\\\]+',' ',text)\n",
        "    ## remove extra whitespace\n",
        "    text = re.sub('\\s+', ' ', text)  \n",
        "    #Stemming may it is not important in the task!, for chractrize the dialects.\n",
        "    #text = stem(text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "hBtc65G5HsRj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83neHf3-JS0r",
        "outputId": "d4e69dbd-e7f8-4e35-8e4a-12c9f15f1f89"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_PA ():\n",
        "    PA = pickle.load(open('/content/drive/MyDrive/PA.pkl', 'rb'))\n",
        "    return PA"
      ],
      "metadata": {
        "id": "TZHTi8-NLaqF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_embedding ():\n",
        "    vec = pickle.load(open('/content/drive/MyDrive/vectorizer.pkl', 'rb'))\n",
        "    return vec"
      ],
      "metadata": {
        "id": "iy_9wKotLln9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce (copus , vec):\n",
        "    X = vec.transform(copus)\n",
        "    X = coo_matrix(X)\n",
        "    tensor_X = torch.sparse_coo_tensor([X.row , X.col],X.data , dtype = torch.float)\n",
        "    reducer = MLP(2,tensor_X.shape[1],1000,10000)\n",
        "    reducer.apply(init_weights)\n",
        "    Z = reducer(tensor_X)\n",
        "    Z = Z.detach().numpy()\n",
        "    return Z"
      ],
      "metadata": {
        "id": "u9Ty1ONOMAti"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {'IQ': 0, 'LY': 1, 'QA': 2, 'PL': 3, 'SY': 4\n",
        "          , 'TN': 5, 'JO': 6, 'MA': 7, 'SA': 8, 'YE': 9, 'DZ': 10, 'EG': 11,\n",
        "          'LB': 12, 'KW': 13, 'OM': 14, 'SD': 15, 'AE': 16, 'BH': 17}\n",
        "langs = {v:k for k,v in labels.items()}"
      ],
      "metadata": {
        "id": "dUE8gRnEP8WT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\" , methods = ['POST'])\n",
        "def PA():\n",
        "  data = request.json\n",
        "  copus = [clean_text(text) for text in data]\n",
        "  vec = load_embedding()\n",
        "  emb = reduce(copus , vec)\n",
        "  PA_ML = get_PA()\n",
        "  labels = PA_ML.predict(emb)\n",
        "  out = [langs[l] for l in labels]\n",
        "  return jsonify(out)\n",
        "\n",
        "app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6IUO8ipJWij",
        "outputId": "f2ed2d90-0fb5-4481-de81-69535fbeb356"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://bef7-35-204-212-163.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "127.0.0.1 - - [10/Mar/2022 09:56:53] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "127.0.0.1 - - [10/Mar/2022 09:57:10] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    }
  ]
}